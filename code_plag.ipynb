{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fea3866-318e-4e8f-8bb0-149fab52b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beea12de-bfa3-4c75-bf92-f124d27ee6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_code(code):\n",
    "    code = re.sub(r'\\'\\'\\'.*?\\'\\'\\'', '', code, flags=re.DOTALL)\n",
    "    code = re.sub(r'\\\"\\\"\\\".*?\\\"\\\"\\\"', '', code, flags=re.DOTALL) \n",
    "    code = re.sub(r'#.*', '', code) \n",
    "    \n",
    "    code = re.sub(r'^\\s*(import|from)\\s+[^\\n]+', '', code, flags=re.MULTILINE)\n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c54db0a-77f4-46ed-808d-4ddab6e3bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_files = [doc for doc in os.listdir('code_data') if doc.endswith('.py')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6709d20e-2664-4b8d-819e-244bf5f7b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_code = [preprocess_code(open(os.path.join('code_data', _file), encoding='utf-8', errors='ignore').read())\n",
    "                for _file in student_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3968b451-00f0-464f-8915-15da6691a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(Text): \n",
    "    return TfidfVectorizer(token_pattern=r'\\b\\w+\\b').fit_transform(Text).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1416155b-1bd9-408a-81d7-0e346eb20734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(doc1, doc2): \n",
    "    return cosine_similarity([doc1, doc2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "427ec87e-fd43-4d16-b41b-4a42294bd0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorize(student_code)\n",
    "s_vectors = list(zip(student_files, vectors))\n",
    "plagiarism_results = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7208d0d-a569-41db-b74a-dfc2ad742923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_plagiarism():\n",
    "    for student_a, text_vector_a in s_vectors:\n",
    "        for student_b, text_vector_b in s_vectors:\n",
    "            if student_a != student_b:\n",
    "                sim_score = similarity(text_vector_a, text_vector_b)[0][1]\n",
    "                if sim_score > 0.5:\n",
    "                    student_pair = sorted((student_a, student_b))\n",
    "                    score = (student_pair[0], student_pair[1], sim_score)\n",
    "                    plagiarism_results.add(score)\n",
    "    return plagiarism_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "270b603b-2932-4b2b-93ca-d4b7189e481f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a34.py vs a45.py: Similarity Score: 0.98\n",
      "a13.py vs a41.py: Similarity Score: 0.79\n",
      "a3.py vs a5.py: Similarity Score: 0.56\n",
      "a5.py vs a7.py: Similarity Score: 0.73\n",
      "a12.py vs a30.py: Similarity Score: 0.77\n",
      "a2.py vs a25.py: Similarity Score: 0.86\n",
      "a10.py vs a7.py: Similarity Score: 0.88\n",
      "a10.py vs a5.py: Similarity Score: 0.71\n",
      "a14.py vs a26.py: Similarity Score: 0.68\n",
      "a43.py vs a47.py: Similarity Score: 0.73\n",
      "a10.py vs a3.py: Similarity Score: 0.65\n",
      "a4.py vs a5.py: Similarity Score: 0.53\n",
      "a3.py vs a7.py: Similarity Score: 0.64\n",
      "a36.py vs a44.py: Similarity Score: 0.57\n"
     ]
    }
   ],
   "source": [
    "for data in check_plagiarism():\n",
    "    print(f'{data[0]} vs {data[1]}: Similarity Score: {data[2]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedb1225-487f-49ef-b787-844fd347857d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe68ef4-0467-4c3b-b89a-967477681bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a5.py vs a10.py: Similarity Score: 0.71\n",
      "a5.py vs a3.py: Similarity Score: 0.56\n",
      "a5.py vs a4.py: Similarity Score: 0.53\n",
      "a5.py vs a7.py: Similarity Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def preprocess_code(code):\n",
    "    code = re.sub(r'\\'\\'\\'.*?\\'\\'\\'', '', code, flags=re.DOTALL)\n",
    "    code = re.sub(r'\\\"\\\"\\\".*?\\\"\\\"\\\"', '', code, flags=re.DOTALL) \n",
    "    code = re.sub(r'#.*', '', code) \n",
    "    code = re.sub(r'^\\s*(import|from)\\s+[^\\n]+', '', code, flags=re.MULTILINE)\n",
    "    return code\n",
    "\n",
    "def vectorize(text): \n",
    "    return TfidfVectorizer(token_pattern=r'\\b\\w+\\b').fit_transform(text).toarray()\n",
    "\n",
    "def similarity(doc1, doc2): \n",
    "    return cosine_similarity([doc1, doc2])[0][1]\n",
    "\n",
    "def check_similarity_with_input(input_file_path):\n",
    "    input_code = preprocess_code(open(input_file_path, encoding='utf-8', errors='ignore').read())\n",
    "    \n",
    "    student_files = [doc for doc in os.listdir('code_data') if doc.endswith('.py') and doc != os.path.basename(input_file_path)]\n",
    "    student_code = [preprocess_code(open(os.path.join('code_data', _file), encoding='utf-8', errors='ignore').read())\n",
    "                    for _file in student_files]\n",
    "    \n",
    "    all_texts = [input_code] + student_code\n",
    "    vectors = vectorize(all_texts)\n",
    "    \n",
    "    input_vector = vectors[0]\n",
    "    plagiarism_results = []\n",
    "    for i, vector in enumerate(vectors[1:], 1):\n",
    "        sim_score = similarity(input_vector, vector)\n",
    "        if sim_score > 0.5:\n",
    "            plagiarism_results.append((os.path.basename(input_file_path), student_files[i-1], sim_score))\n",
    "    \n",
    "    return plagiarism_results\n",
    "\n",
    "input_file = 'code_data/a5.py'\n",
    "results = check_similarity_with_input(input_file)\n",
    "for data in results:\n",
    "    print(f'{data[0]} vs {data[1]}: Similarity Score: {data[2]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60574ff-895c-4d8f-a654-80038cdd1dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ea3120-d824-4453-935a-3c1b74972150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a5.py vs a1.py: Similarity Score: 0.83\n",
      "a5.py vs a10.py: Similarity Score: 0.87\n",
      "a5.py vs a2.py: Similarity Score: 0.72\n",
      "a5.py vs a3.py: Similarity Score: 0.79\n",
      "a5.py vs a4.py: Similarity Score: 0.62\n",
      "a5.py vs a47.py: Similarity Score: 0.51\n",
      "a5.py vs a6.py: Similarity Score: 0.66\n",
      "a5.py vs a7.py: Similarity Score: 0.88\n",
      "a5.py vs a8.py: Similarity Score: 0.62\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "def preprocess_code(code):\n",
    "    code = re.sub(r'\\'\\'\\'.*?\\'\\'\\'', '', code, flags=re.DOTALL)\n",
    "    code = re.sub(r'\\\"\\\"\\\".*?\\\"\\\"\\\"', '', code, flags=re.DOTALL) \n",
    "    code = re.sub(r'#.*', '', code) \n",
    "    code = re.sub(r'^\\s*(import|from)\\s+[^\\n]+', '', code, flags=re.MULTILINE)\n",
    "    return code\n",
    "\n",
    "def train_doc2vec_model(texts):\n",
    "    tagged_data = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(texts)]\n",
    "    model = Doc2Vec(vector_size=100, window=5, min_count=1, epochs=100, dm=1)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    return model\n",
    "\n",
    "def check_similarity_with_input(input_file_path):\n",
    "    input_code = preprocess_code(open(input_file_path, encoding='utf-8', errors='ignore').read())\n",
    "    \n",
    "    student_files = [doc for doc in os.listdir('code_data') if doc.endswith('.py') and doc != os.path.basename(input_file_path)]\n",
    "    student_code = [preprocess_code(open(os.path.join('code_data', _file), encoding='utf-8', errors='ignore').read())\n",
    "                    for _file in student_files]\n",
    "    \n",
    "    all_texts = [input_code] + student_code\n",
    "    model = train_doc2vec_model(all_texts)\n",
    "    \n",
    "    input_vector = model.infer_vector(input_code.split())\n",
    "    plagiarism_results = []\n",
    "    \n",
    "    for i, code in enumerate(student_code):\n",
    "        sim_score = model.similarity_unseen_docs(input_code.split(), code.split())\n",
    "        if sim_score > 0.5:\n",
    "            plagiarism_results.append((os.path.basename(input_file_path), student_files[i], sim_score))\n",
    "    \n",
    "    return plagiarism_results\n",
    "\n",
    "input_file = 'code_data/a5.py'\n",
    "results = check_similarity_with_input(input_file)\n",
    "for data in results:\n",
    "    print(f'{data[0]} vs {data[1]}: Similarity Score: {data[2]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401597ac-dc9e-40fa-bc36-c6049bc55871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de9f87bd-64c2-411d-88d0-d0fd1dd169c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Scores for files with > 50% similarity:\n",
      "a5.py vs a1.py: Similarity Score: 0.83\n",
      "a5.py vs a10.py: Similarity Score: 0.87\n",
      "a5.py vs a2.py: Similarity Score: 0.72\n",
      "a5.py vs a3.py: Similarity Score: 0.79\n",
      "a5.py vs a4.py: Similarity Score: 0.62\n",
      "a5.py vs a47.py: Similarity Score: 0.51\n",
      "a5.py vs a6.py: Similarity Score: 0.66\n",
      "a5.py vs a7.py: Similarity Score: 0.88\n",
      "a5.py vs a8.py: Similarity Score: 0.62\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the file name to view matched lines (e.g., 'file.py'):  a8.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matching lines between a5.py and a8.py:\n",
      "Matching Sections:\n",
      "- def \n",
      "- p\n",
      "- h\n",
      "- s\n",
      "- : {\n",
      "- }\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def preprocess_code(code):\n",
    "    code = re.sub(r'\\'\\'\\'.*?\\'\\'\\'', '', code, flags=re.DOTALL)\n",
    "    code = re.sub(r'\\\"\\\"\\\".*?\\\"\\\"\\\"', '', code, flags=re.DOTALL) \n",
    "    code = re.sub(r'#.*', '', code) \n",
    "    code = re.sub(r'^\\s*(import|from)\\s+[^\\n]+', '', code, flags=re.MULTILINE)\n",
    "    return code\n",
    "\n",
    "def train_doc2vec_model(texts):\n",
    "    tagged_data = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(texts)]\n",
    "    model = Doc2Vec(vector_size=100, window=5, min_count=1, epochs=100, dm=1)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    return model\n",
    "\n",
    "def get_matching_blocks(text1, text2):\n",
    "    s = SequenceMatcher(None, text1, text2)\n",
    "    matching_blocks = s.get_matching_blocks()\n",
    "    matches = []\n",
    "    for match in matching_blocks:\n",
    "        if match.size > 0:\n",
    "            matches.append(text1[match.a: match.a + match.size])\n",
    "    return matches\n",
    "\n",
    "def check_similarity_with_input(input_file_path):\n",
    "    input_code = preprocess_code(open(input_file_path, encoding='utf-8', errors='ignore').read())\n",
    "    \n",
    "    student_files = [doc for doc in os.listdir('code_data') if doc.endswith('.py') and doc != os.path.basename(input_file_path)]\n",
    "    student_code = [preprocess_code(open(os.path.join('code_data', _file), encoding='utf-8', errors='ignore').read())\n",
    "                    for _file in student_files]\n",
    "    \n",
    "    all_texts = [input_code] + student_code\n",
    "    model = train_doc2vec_model(all_texts)\n",
    "    \n",
    "    input_vector = model.infer_vector(input_code.split())\n",
    "    plagiarism_results = []\n",
    "    \n",
    "    for i, code in enumerate(student_code):\n",
    "        sim_score = model.similarity_unseen_docs(input_code.split(), code.split())\n",
    "        if sim_score > 0.5:\n",
    "            plagiarism_results.append((os.path.basename(input_file_path), student_files[i], sim_score, code))\n",
    "    \n",
    "    return plagiarism_results\n",
    "\n",
    "def display_matching_sections(input_code, code):\n",
    "    matches = get_matching_blocks(input_code, code)\n",
    "    print(\"Matching Sections:\")\n",
    "    for match in matches:\n",
    "        print(f\"- {match}\")\n",
    "\n",
    "input_file = 'code_data/a5.py'\n",
    "results = check_similarity_with_input(input_file)\n",
    "print(\"Similarity Scores for files with > 50% similarity:\")\n",
    "for data in results:\n",
    "    print(f'{data[0]} vs {data[1]}: Similarity Score: {data[2]:.2f}')\n",
    "\n",
    "file_to_check = input(\"\\nEnter the file name to view matched lines (e.g., 'file.py'): \")\n",
    "\n",
    "for data in results:\n",
    "    if data[1] == file_to_check:\n",
    "        print(f'\\nMatching lines between {data[0]} and {data[1]}:')\n",
    "        display_matching_sections(preprocess_code(open(input_file, encoding='utf-8', errors='ignore').read()), data[3])\n",
    "        break\n",
    "else:\n",
    "    print(\"File not found in similarity results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba2af6-6c5d-4d57-b54d-a140f8182af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b5159-55c4-4768-8f0a-b3c485463f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
