{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62fbfdb-6178-45d4-a808-9714d4a6cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df41ba0-e50a-48d1-ba92-4b3b487d3669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Gowri\n",
      "[nltk_data]     sri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e255fb5-f24c-4dad-adf5-fa9646cef368",
   "metadata": {},
   "outputs": [],
   "source": [
    "telugu_stopwords = set([\n",
    "    \"ఇది\", \"ఒక\", \"ఈ\", \"మరియు\", \"కాని\", \"అందుకే\", \"మీరు\", \"వారిని\", \"ఉన్న\",\n",
    "    \"ఉంటే\", \"ఎలా\", \"ఎందుకు\", \"కాబట్టి\", \"ఎప్పుడు\", \"ఇంకా\", \"మాత్రమే\", \"మొత్తం\",\n",
    "    \"నేను\", \"నీకు\", \"వారు\", \"ఆది\", \"మంచి\", \"తరువాత\", \"కూడా\", \"అక్కడ\", \"మీ\", \n",
    "    \"వెంట\", \"అంటే\", \"ఇంకా\", \"చెప్పారు\", \"అవి\", \"మరి\", \"అందరూ\", \"అప్పటికీ\", \n",
    "    \"దాని\", \"అంతా\", \"ఎవరూ\", \"లేదా\", \"ఏది\", \"ఎప్పుడూ\", \"ఎక్కడా\", \"అవును\", \n",
    "    \"కాబట్టి\", \"అప్పుడు\", \"అందువల్ల\", \"విషయం\", \"ఎందుకంటే\", \"వద్ద\", \"చేత\", \"పైన\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708b5be6-fa02-49f8-9ad5-8bd46217d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = unicodedata.normalize('NFKC', text)  \n",
    "    telugu_punctuation = '।॥,!.?।'  \n",
    "    text = re.sub(f\"[{telugu_punctuation}]\", \"\", text)  \n",
    "    tokens = text.split() \n",
    "    tokens = [word for word in tokens if word not in telugu_stopwords] \n",
    "    return \" \".join(tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303af59d-d156-4a90-bc43-effbd3cb7eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'telugu_text'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1624833-7d8f-46dc-9da0-8272f5cb5ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'కుక్కలు మానవ ఆరోగ్యంపై ఎంతో ప్రభావాన్ని చూపగలవు ప్రత్యేకంగా కుక్కలు ఎమోషనల్ సపోర్ట్ జంతువులుగా చాలా ముఖ్యమైన పాత్రను పోషిస్తాయి ఎన్నో మానసిక సమస్యలు ఒత్తిడులు నిరాశలను తగ్గించడంలో కుక్కలు సహాయపడతాయి కొన్ని అధ్యయనాలు కుక్కలు యజమానులకు ఆత్మవిశ్వాసాన్ని పెంచడం ఒత్తిడి హార్మోన్లను తగ్గించడం వంటి అనేక ఆరోగ్య ప్రయోజనాలను కలిగిస్తాయని సూచిస్తున్నాయి ముఖ్యంగా పిల్లల మానసిక ఆరోగ్యంపై కుక్కల ప్రభావం ఎక్కువగా ఉంటుంది కుక్కల సహవాసం వలన చిన్న పిల్లలు బాధ్యతాయుతంగా ఉండడం నేర్చుకుంటారు మనుషుల శారీరక ఆరోగ్యానికి బహుముఖ పాత్ర పోషిస్తాయి ముఖ్యంగా ఫిజికల్ యాక్టివిటీని ప్రోత్సహించడం ద్వారా హృదయ సంబంధ వ్యాధుల ప్రమాదాన్ని తగ్గించగలవు కుక్కలతో సహవాసం అనేక ఆధ్యాత్మిక మానసిక ప్రయోజనాలను కలిగిస్తుంది'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text('''కుక్కలు మానవ ఆరోగ్యంపై ఎంతో ప్రభావాన్ని చూపగలవు. ప్రత్యేకంగా, కుక్కలు ఎమోషనల్ సపోర్ట్ జంతువులుగా చాలా ముఖ్యమైన పాత్రను పోషిస్తాయి. ఎన్నో మానసిక సమస్యలు, ఒత్తిడులు మరియు నిరాశలను తగ్గించడంలో కుక్కలు సహాయపడతాయి. కొన్ని అధ్యయనాలు కుక్కలు యజమానులకు ఆత్మవిశ్వాసాన్ని పెంచడం, ఒత్తిడి హార్మోన్లను తగ్గించడం వంటి అనేక ఆరోగ్య ప్రయోజనాలను కలిగిస్తాయని సూచిస్తున్నాయి.\n",
    "\n",
    "ముఖ్యంగా పిల్లల మానసిక ఆరోగ్యంపై కుక్కల ప్రభావం ఎక్కువగా ఉంటుంది. కుక్కల సహవాసం వలన చిన్న పిల్లలు బాధ్యతాయుతంగా ఉండడం నేర్చుకుంటారు. అవి మనుషుల శారీరక ఆరోగ్యానికి కూడా బహుముఖ పాత్ర పోషిస్తాయి, ముఖ్యంగా ఫిజికల్ యాక్టివిటీని ప్రోత్సహించడం ద్వారా హృదయ సంబంధ వ్యాధుల ప్రమాదాన్ని తగ్గించగలవు. కుక్కలతో సహవాసం అనేక ఆధ్యాత్మిక మరియు మానసిక ప్రయోజనాలను కలిగిస్తుంది.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01d726de-ca66-4538-b32a-00621a2bc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_texts = []\n",
    "file_names = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65059b88-4137-444b-8fb9-e72bc02fbaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.txt'): \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        preprocessed_text = preprocess_text(text)\n",
    "        \n",
    "        file_texts.append(preprocessed_text)\n",
    "        file_names.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be04aa2d-c16f-47f7-b1af-0f4b2323bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(file_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a243e45-2509-4626-a89f-9c955a14cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51146933-112a-44e3-ac9b-b52084068f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plagiarism detected between 11.txt and 43.txt with similarity: 0.5371\n",
      "Plagiarism detected between 22.txt and seven.txt with similarity: 0.5476\n",
      "Plagiarism detected between 34.txt and three.txt with similarity: 0.5703\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(file_names)):\n",
    "    for j in range(i + 1, len(file_names)):  \n",
    "        similarity_score = similarity_matrix[i][j]\n",
    "        if similarity_score > 0.5: \n",
    "            print(f\"Plagiarism detected between {file_names[i]} and {file_names[j]} with similarity: {similarity_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b5684-9e75-488d-83cc-f15286dcd8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf29d75d-3b25-483a-92e3-28f5879a0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two.txt vs 13.txt: Similarity Score: 0.3100\n",
      "two.txt vs 15.txt: Similarity Score: 0.3801\n",
      "two.txt vs 16.txt: Similarity Score: 0.3230\n",
      "two.txt vs 17.txt: Similarity Score: 0.3211\n",
      "two.txt vs 19.txt: Similarity Score: 0.3306\n",
      "two.txt vs 20.txt: Similarity Score: 0.4634\n",
      "two.txt vs 21.txt: Similarity Score: 0.3212\n",
      "two.txt vs 24.txt: Similarity Score: 0.3732\n",
      "two.txt vs 31.txt: Similarity Score: 0.3123\n",
      "two.txt vs 41.txt: Similarity Score: 0.3517\n",
      "two.txt vs 50.txt: Similarity Score: 0.3454\n",
      "two.txt vs eight.txt: Similarity Score: 0.3218\n",
      "two.txt vs six.txt: Similarity Score: 0.3413\n",
      "two.txt vs ten.txt: Similarity Score: 0.3935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Gowri\n",
      "[nltk_data]     sri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "telugu_stopwords = set([\n",
    "    \"ఇది\", \"ఒక\", \"ఈ\", \"మరియు\", \"కాని\", \"అందుకే\", \"మీరు\", \"వారిని\", \"ఉన్న\",\n",
    "    \"ఉంటే\", \"ఎలా\", \"ఎందుకు\", \"కాబట్టి\", \"ఎప్పుడు\", \"ఇంకా\", \"మాత్రమే\", \"మొత్తం\",\n",
    "    \"నేను\", \"నీకు\", \"వారు\", \"ఆది\", \"మంచి\", \"తరువాత\", \"కూడా\", \"అక్కడ\", \"మీ\", \n",
    "    \"వెంట\", \"అంటే\", \"ఇంకా\", \"చెప్పారు\", \"అవి\", \"మరి\", \"అందరూ\", \"అప్పటికీ\", \n",
    "    \"దాని\", \"అంతా\", \"ఎవరూ\", \"లేదా\", \"ఏది\", \"ఎప్పుడూ\", \"ఎక్కడా\", \"అవును\", \n",
    "    \"కాబట్టి\", \"అప్పుడు\", \"అందువల్ల\", \"విషయం\", \"ఎందుకంటే\", \"వద్ద\", \"చేత\", \"పైన\"\n",
    "]) \n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    telugu_punctuation = '।॥,!.?।'\n",
    "    text = re.sub(f\"[{telugu_punctuation}]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in telugu_stopwords]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def check_similarity_with_input(input_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        input_text = preprocess_text(file.read())\n",
    "    \n",
    "    folder_path = 'telugu_text'\n",
    "    file_texts = []\n",
    "    file_names = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt') and filename != os.path.basename(input_file_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = preprocess_text(file.read())\n",
    "            file_texts.append(text)\n",
    "            file_names.append(filename)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([input_text] + file_texts)\n",
    "    \n",
    "    input_vector = tfidf_matrix[0]\n",
    "    similarity_scores = cosine_similarity(input_vector, tfidf_matrix[1:])[0]\n",
    "    \n",
    "    results = []\n",
    "    for i, score in enumerate(similarity_scores):\n",
    "        if score > 0.3:\n",
    "            results.append((os.path.basename(input_file_path), file_names[i], score))\n",
    "    \n",
    "    return results\n",
    "\n",
    "input_file = 'telugu_text/two.txt'\n",
    "results = check_similarity_with_input(input_file)\n",
    "for data in results:\n",
    "    print(f'{data[0]} vs {data[1]}: Similarity Score: {data[2]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee64678-321e-4be8-a4e5-df41e04a1a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f095bce-06f0-4471-a3bf-d11fe5b59a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Gowri\n",
      "[nltk_data]     sri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Scores for files with > 30% similarity:\n",
      "two.txt vs 13.txt: Similarity Score: 0.3100\n",
      "two.txt vs 15.txt: Similarity Score: 0.3801\n",
      "two.txt vs 16.txt: Similarity Score: 0.3230\n",
      "two.txt vs 17.txt: Similarity Score: 0.3211\n",
      "two.txt vs 19.txt: Similarity Score: 0.3306\n",
      "two.txt vs 20.txt: Similarity Score: 0.4634\n",
      "two.txt vs 21.txt: Similarity Score: 0.3212\n",
      "two.txt vs 24.txt: Similarity Score: 0.3732\n",
      "two.txt vs 31.txt: Similarity Score: 0.3123\n",
      "two.txt vs 41.txt: Similarity Score: 0.3517\n",
      "two.txt vs 50.txt: Similarity Score: 0.3454\n",
      "two.txt vs eight.txt: Similarity Score: 0.3218\n",
      "two.txt vs six.txt: Similarity Score: 0.3413\n",
      "two.txt vs ten.txt: Similarity Score: 0.3935\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the file name to view matched lines (e.g., 'file.txt'):  six.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matching words between two.txt and six.txt:\n",
      "Matching Words:\n",
      "- కుక్కలు\n",
      "- అత్యంత\n",
      "- కుక్కలు\n",
      "- కలిగి ఉంటాయి\n",
      "- కుక్కలు\n",
      "- ఉంటాయి\n",
      "- కుక్కలు\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from difflib import SequenceMatcher\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "telugu_stopwords = set([\n",
    "    \"ఇది\", \"ఒక\", \"ఈ\", \"మరియు\", \"కాని\", \"అందుకే\", \"మీరు\", \"వారిని\", \"ఉన్న\",\n",
    "    \"ఉంటే\", \"ఎలా\", \"ఎందుకు\", \"కాబట్టి\", \"ఎప్పుడు\", \"ఇంకా\", \"మాత్రమే\", \"మొత్తం\",\n",
    "    \"నేను\", \"నీకు\", \"వారు\", \"ఆది\", \"మంచి\", \"తరువాత\", \"కూడా\", \"అక్కడ\", \"మీ\", \n",
    "    \"వెంట\", \"అంటే\", \"ఇంకా\", \"చెప్పారు\", \"అవి\", \"మరి\", \"అందరూ\", \"అప్పటికీ\", \n",
    "    \"దాని\", \"అంతా\", \"ఎవరూ\", \"లేదా\", \"ఏది\", \"ఎప్పుడూ\", \"ఎక్కడా\", \"అవును\", \n",
    "    \"కాబట్టి\", \"అప్పుడు\", \"అందువల్ల\", \"విషయం\", \"ఎందుకంటే\", \"వద్ద\", \"చేత\", \"పైన\"\n",
    "])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    telugu_punctuation = '।॥,!.?।'\n",
    "    text = re.sub(f\"[{telugu_punctuation}]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in telugu_stopwords]\n",
    "    return \" \".join(tokens)  \n",
    "\n",
    "def get_matching_words(words1, words2):\n",
    "    s = SequenceMatcher(None, words1, words2)\n",
    "    matching_blocks = s.get_matching_blocks()\n",
    "    matches = []\n",
    "    for match in matching_blocks:\n",
    "        if match.size > 0:\n",
    "            matched_words = words1[match.a: match.a + match.size]\n",
    "            if len(matched_words) > 0:\n",
    "                matches.append(\" \".join(matched_words))  \n",
    "    return matches\n",
    "\n",
    "def check_similarity_with_input(input_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        input_text = preprocess_text(file.read())  \n",
    "    \n",
    "    folder_path = 'telugu_text'\n",
    "    file_texts = []\n",
    "    file_names = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt') and filename != os.path.basename(input_file_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = preprocess_text(file.read()) \n",
    "            file_texts.append(text)\n",
    "            file_names.append(filename)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()  \n",
    "    tfidf_matrix = vectorizer.fit_transform([input_text] + file_texts)\n",
    "    \n",
    "    input_vector = tfidf_matrix[0]\n",
    "    similarity_scores = cosine_similarity(input_vector, tfidf_matrix[1:])[0]\n",
    "    \n",
    "    results = []\n",
    "    for i, score in enumerate(similarity_scores):\n",
    "        if score > 0.3: \n",
    "            results.append((os.path.basename(input_file_path), file_names[i], score))\n",
    "    \n",
    "    return results, file_texts, input_text\n",
    "\n",
    "def display_matching_sections(input_text, compared_text):\n",
    "    input_words = input_text.split()  \n",
    "    compared_words = compared_text.split() \n",
    "    matches = get_matching_words(input_words, compared_words)\n",
    "    print(\"Matching Words:\")\n",
    "    \n",
    "    for match in matches:\n",
    "        if match.strip(): \n",
    "            print(f\"- {match}\")\n",
    "\n",
    "input_file = 'telugu_text/two.txt'\n",
    "results, file_texts, input_text = check_similarity_with_input(input_file)\n",
    "\n",
    "print(\"Similarity Scores for files with > 30% similarity:\")\n",
    "for data in results:\n",
    "    print(f'{data[0]} vs {data[1]}: Similarity Score: {data[2]:.4f}')\n",
    "\n",
    "file_to_check = input(\"\\nEnter the file name to view matched lines (e.g., 'file.txt'): \")\n",
    "\n",
    "for data in results:\n",
    "    if data[1] == file_to_check:\n",
    "        print(f'\\nMatching words between {data[0]} and {data[1]}:')\n",
    "        index = [i for i, f in enumerate(results) if f[1] == file_to_check][0]\n",
    "        display_matching_sections(input_text, file_texts[index])\n",
    "        break\n",
    "else:\n",
    "    print(\"File not found in similarity results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99a8d7-8d1f-462c-9932-a0be3b19e75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
